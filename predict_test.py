# advanced_metrics_analysis.py
import json
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from ultralytics import YOLO
import numpy as np


class YOLOEvaluator:
    def __init__(self, model_path, data_yaml):
        self.model_path = model_path
        self.data_yaml = data_yaml
        self.model = YOLO(model_path)
        self.metrics = None

    def comprehensive_evaluation(self, split='test'):
        """æ‰§è¡Œå…¨é¢çš„æ¨¡å‹è¯„ä¼°"""

        print("ğŸ” æ‰§è¡Œå…¨é¢æ¨¡å‹è¯„ä¼°...")

        # åŸºç¡€éªŒè¯
        self.metrics = self.model.val(
            data=self.data_yaml,
            split=split,
            save_json=True,
            plots=True,
            conf=0.001,
            iou=0.6,
            device=0
        )

        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self._generate_detailed_report()

        return self.metrics

    def _generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†è¯„ä¼°æŠ¥å‘Š"""

        print("\n" + "=" * 80)
        print("ğŸ“ˆ è¯¦ç»†è¯„ä¼°æŠ¥å‘Š")
        print("=" * 80)

        # 1. åŸºç¡€æ€§èƒ½æŒ‡æ ‡
        self._print_basic_metrics()

        # 2. å„ç±»åˆ«æ€§èƒ½
        self._print_class_metrics()

        # 3. æ··æ·†çŸ©é˜µåˆ†æ
        self._analyze_confusion_matrix()

        # 4. æ€§èƒ½å»ºè®®
        self._provide_recommendations()

    def _print_basic_metrics(self):
        """æ‰“å°åŸºç¡€æ€§èƒ½æŒ‡æ ‡"""

        print("\nğŸ“Š åŸºç¡€æ€§èƒ½æŒ‡æ ‡:")
        print(f"  â€¢ mAP@0.5:       {self.metrics.box.map50:.4f}")
        print(f"  â€¢ mAP@0.5:0.95:  {self.metrics.box.map:.4f}")
        print(f"  â€¢ ç²¾ç¡®ç‡:        {self.metrics.box.precision:.4f}")
        print(f"  â€¢ å¬å›ç‡:        {self.metrics.box.recall:.4f}")

        # è®¡ç®—F1åˆ†æ•°
        precision = self.metrics.box.precision
        recall = self.metrics.box.recall
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        print(f"  â€¢ F1åˆ†æ•°:        {f1:.4f}")

        # æ¨ç†é€Ÿåº¦
        if hasattr(self.metrics, 'speed'):
            speed = self.metrics.speed
            print(f"  â€¢ æ¨ç†é€Ÿåº¦:      {speed.get('inference', 0):.2f} ms/å›¾åƒ")
            print(f"  â€¢ FPS:          {1000 / speed.get('inference', 1):.2f}")

    def _print_class_metrics(self):
        """æ‰“å°å„ç±»åˆ«æŒ‡æ ‡"""

        if hasattr(self.metrics.box, 'aps') and self.metrics.box.aps is not None:
            print(f"\nğŸ¯ å„ç±»åˆ«AP (å…±{len(self.metrics.box.aps)}ä¸ªç±»åˆ«):")

            # æŒ‰APå€¼æ’åº
            sorted_aps = sorted(enumerate(self.metrics.box.aps),
                                key=lambda x: x[1], reverse=True)

            for i, (class_id, ap) in enumerate(sorted_aps):
                status = "âœ…" if ap > 0.5 else "âš ï¸" if ap > 0.3 else "âŒ"
                print(f"  {status} ç±»åˆ« {class_id}: AP = {ap:.4f}")

                # åªæ˜¾ç¤ºå‰10ä¸ªå’Œå10ä¸ª
                if i == 9 and len(sorted_aps) > 20:
                    print(f"  ... çœç•¥ä¸­é—´ {len(sorted_aps) - 20} ä¸ªç±»åˆ« ...")
                    break

    def _analyze_confusion_matrix(self):
        """åˆ†ææ··æ·†çŸ©é˜µï¼ˆå¦‚æœå¯ç”¨ï¼‰"""

        # æ£€æŸ¥æ˜¯å¦æœ‰æ··æ·†çŸ©é˜µæ•°æ®
        results_dir = self.metrics.save_dir
        cm_path = os.path.join(results_dir, 'confusion_matrix.png')

        if os.path.exists(cm_path):
            print(f"\nğŸ”€ æ··æ·†çŸ©é˜µå·²ç”Ÿæˆ: {cm_path}")
        else:
            print("\nğŸ”€ æ··æ·†çŸ©é˜µ: æœªç”Ÿæˆæˆ–ä¸å¯ç”¨")

    def _provide_recommendations(self):
        """åŸºäºæŒ‡æ ‡æä¾›æ”¹è¿›å»ºè®®"""

        print("\nğŸ’¡ æ€§èƒ½åˆ†æä¸å»ºè®®:")

        map50 = self.metrics.box.map50
        precision = self.metrics.box.precision
        recall = self.metrics.box.recall

        if map50 < 0.3:
            print("  âŒ æ¨¡å‹æ€§èƒ½è¾ƒå·®ï¼Œå»ºè®®:")
            print("     - æ£€æŸ¥æ•°æ®è´¨é‡")
            print("     - å¢åŠ è®­ç»ƒè½®æ¬¡")
            print("     - è°ƒæ•´æ•°æ®å¢å¼º")
        elif map50 < 0.6:
            print("  âš ï¸ æ¨¡å‹æ€§èƒ½ä¸­ç­‰ï¼Œå»ºè®®:")
            print("     - å¾®è°ƒè¶…å‚æ•°")
            print("     - å¢åŠ å›°éš¾æ ·æœ¬")
            print("     - å°è¯•ä¸åŒå°ºå¯¸è®­ç»ƒ")
        else:
            print("  âœ… æ¨¡å‹æ€§èƒ½è‰¯å¥½!")

        # ç²¾ç¡®ç‡-å¬å›ç‡å¹³è¡¡å»ºè®®
        if precision > recall + 0.2:
            print("  ğŸ“‰ å¬å›ç‡åä½ï¼Œå»ºè®®é™ä½ç½®ä¿¡åº¦é˜ˆå€¼")
        elif recall > precision + 0.2:
            print("  ğŸ“ˆ ç²¾ç¡®ç‡åä½ï¼Œå»ºè®®æé«˜ç½®ä¿¡åº¦é˜ˆå€¼")

    def compare_with_baseline(self, baseline_metrics_path):
        """ä¸åŸºçº¿æ¨¡å‹æ¯”è¾ƒ"""

        try:
            with open(baseline_metrics_path, 'r') as f:
                baseline_metrics = json.load(f)

            current_map = self.metrics.box.map
            baseline_map = baseline_metrics.get('map', 0)

            improvement = current_map - baseline_map

            print(f"\nğŸ“Š ä¸åŸºçº¿æ¯”è¾ƒ:")
            print(f"  â€¢ å½“å‰mAP: {current_map:.4f}")
            print(f"  â€¢ åŸºçº¿mAP: {baseline_map:.4f}")
            print(f"  â€¢ æ”¹è¿›:    {improvement:+.4f} ({improvement / baseline_map * 100:+.1f}%)")

        except Exception as e:
            print(f"âš ï¸ åŸºçº¿æ¯”è¾ƒå¤±è´¥: {e}")


def main():
    # é…ç½®
    evaluator = YOLOEvaluator(
        model_path='runs/detect/train3/weights/best.pt',
        data_yaml='datasets/dataset.yaml'
    )

    # æ‰§è¡Œå…¨é¢è¯„ä¼°
    metrics = evaluator.comprehensive_evaluation(split='test')

    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_path = 'runs/val/detailed_evaluation_report.txt'
    with open(report_path, 'w', encoding='utf-8') as f:
        import sys
        from io import StringIO

        # é‡å®šå‘è¾“å‡ºåˆ°æ–‡ä»¶
        old_stdout = sys.stdout
        sys.stdout = StringIO()

        evaluator._generate_detailed_report()

        report_content = sys.stdout.getvalue()
        sys.stdout = old_stdout

        f.write(report_content)

    print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


if __name__ == "__main__":
    main()